{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from oss2 import SizedFileAdapter, determine_part_size\n",
    "from oss2.models import PartInfo\n",
    "import oss2\n",
    "\n",
    "def uploadFileOSS(fname,local_fpath):\n",
    "    # 阿里云主账号AccessKey拥有所有API的访问权限，风险很高。强烈建议您创建并使用RAM账号进行API访问或日常运维，请登录 https://ram.console.aliyun.com 创建RAM账号。\n",
    "    auth = oss2.Auth('LTAIj6Mqlb0Jbqo5', 'q8oDj6FNA8b6HuVeMMWCVjgB4XFAtW')\n",
    "    # Endpoint以杭州为例，其它Region请按实际情况填写。\n",
    "    bucket = oss2.Bucket(auth, 'http://oss-cn-hangzhou.aliyuncs.com', 'eyisheng-hangzhou')\n",
    "\n",
    "    key = 'shared/'+fname\n",
    "    filename = local_fpath\n",
    "\n",
    "    total_size = os.path.getsize(filename)\n",
    "    # determine_part_size方法用来确定分片大小。\n",
    "    part_size = determine_part_size(total_size, preferred_size=100000 * 1024)\n",
    "\n",
    "    # 初始化分片。\n",
    "    # 如果需要在初始化分片时设置文件存储类型，请在init_multipart_upload中设置相关headers，参考如下。\n",
    "    # headers = dict()\n",
    "    # headers[\"x-oss-storage-class\"] = \"Standard\"\n",
    "    # upload_id = bucket.init_multipart_upload(key, headers=headers).upload_id\n",
    "    upload_id = bucket.init_multipart_upload(key).upload_id\n",
    "    parts = []\n",
    "\n",
    "    # 逐个上传分片。\n",
    "    with open(filename, 'rb') as fileobj:\n",
    "        part_number = 1\n",
    "        offset = 0\n",
    "        while offset < total_size:\n",
    "            print('upload',part_number)\n",
    "            num_to_upload = min(part_size, total_size - offset)\n",
    "            # SizedFileAdapter(fileobj, size)方法会生成一个新的文件对象，重新计算起始追加位置。\n",
    "            result = bucket.upload_part(key, upload_id, part_number,\n",
    "                                        SizedFileAdapter(fileobj, num_to_upload))\n",
    "            parts.append(PartInfo(part_number, result.etag))\n",
    "\n",
    "            offset += num_to_upload\n",
    "            part_number += 1\n",
    "\n",
    "    # 完成分片上传。\n",
    "    # 如果需要在完成分片上传时设置文件访问权限ACL，请在complete_multipart_upload函数中设置相关headers，参考如下。\n",
    "    # headers = dict()\n",
    "    # headers[\"x-oss-object-acl\"] = oss2.OBJECT_ACL_PRIVATE\n",
    "    # bucket.complete_multipart_upload(key, upload_id, parts, headers=headers)\n",
    "    bucket.complete_multipart_upload(key, upload_id, parts)\n",
    "\n",
    "    # 验证分片上传。\n",
    "    with open(filename, 'rb') as fileobj:\n",
    "        assert bucket.get_object(key).read() == fileobj.read()\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "def downloadFileOSS(fname,local_fpath):\n",
    "    # 阿里云主账号AccessKey拥有所有API的访问权限，风险很高。强烈建议您创建并使用RAM账号进行API访问或日常运维，请登录RAM控制台创建RAM账号。\n",
    "    auth = oss2.Auth('LTAIj6Mqlb0Jbqo5', 'q8oDj6FNA8b6HuVeMMWCVjgB4XFAtW')\n",
    "    # Endpoint以杭州为例，其它Region请按实际情况填写。\n",
    "    bucket = oss2.Bucket(auth, 'http://oss-cn-hangzhou.aliyuncs.com', 'eyisheng-hangzhou')\n",
    "\n",
    "    # 下载OSS文件到本地文件。如果指定的本地文件存在会覆盖，不存在则新建。\n",
    "    #  <yourLocalFile>由本地文件路径加文件名包括后缀组成，例如/users/local/myfile.txt。\n",
    "    bucket.get_object_to_file(os.path.join('shared/',fname), local_fpath)\n",
    "    return\n",
    "\n",
    "def listFileOSS():\n",
    "    # 阿里云主账号AccessKey拥有所有API的访问权限，风险很高。强烈建议您创建并使用RAM账号进行API访问或日常运维，请登录RAM控制台创建RAM账号。\n",
    "    auth = oss2.Auth('LTAIj6Mqlb0Jbqo5', 'q8oDj6FNA8b6HuVeMMWCVjgB4XFAtW')\n",
    "    # Endpoint以杭州为例，其它Region请按实际情况填写。\n",
    "    bucket = oss2.Bucket(auth, 'http://oss-cn-hangzhou.aliyuncs.com', 'eyisheng-hangzhou')\n",
    "\n",
    "    # 列举存储空间下所有文件。\n",
    "    for obj in oss2.ObjectIterator(bucket,prefix='shared/'):\n",
    "        print(obj.key)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared/\n",
      "shared/ResNet_model.zip\n",
      "shared/bi-temp.txt\n",
      "shared/biodata.zip\n",
      "shared/biodata1.zip\n",
      "shared/dataset_new.rar\n",
      "shared/embedding-file.csv\n",
      "shared/metallic1-0.zip\n",
      "shared/metallic1-1.zip\n",
      "shared/metallic1-2.zip\n",
      "shared/metallic1-3.zip\n",
      "shared/model-1.zip\n",
      "shared/model-2.zip\n",
      "shared/recommend-1-all.csv\n",
      "shared/recommend-1-update.csv\n",
      "shared/recommend-1.csv\n",
      "shared/tuples.txt\n"
     ]
    }
   ],
   "source": [
    "listFileOSS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uploadFileOSS(fname='model-2.zip',local_fpath=r'/root/research/jupyter/git-metallic-5-5/metallic/model-1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadFileOSS(,'/root/.cache/torch/checkpoints/ig_resnext101_32x16-c6f796b0.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
